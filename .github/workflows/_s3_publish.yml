name: Publish Binaries to S3

on:
  workflow_call:
    inputs:
      target_type:
        description: 'Target type for publishing (edge, nightly, release, non-release)'
        required: true
        type: string
      environment:
        description: 'Environment for publishing (e.g. release)'
        required: false
        default: 'release'
        type: string
      s3_base_prefix:
        description: |
          Base prefix for S3 objects (default: "public").
          This prefix is included in S3 paths but excluded from manifest paths
          because CloudFront serves this prefix as the root domain
          (e.g., get.bacalhau.org/ maps to s3://bucket/public/)
        required: false
        default: 'public'
        type: string
    secrets:
      AWS_ACCESS_KEY_ID:
        required: true
      AWS_SECRET_ACCESS_KEY:
        required: true

jobs:
  publish-to-s3:
    name: Publish to S3
    runs-on: ubuntu-latest
    environment: ${{ inputs.environment }}  # Use the specified environment
    permissions:
      contents: read
      id-token: write

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: "0"  # Fetch all history for proper versioning

      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: bacalhau-*
          path: artifacts

      - name: List all downloaded artifacts
        run: |
          echo "==== LISTING ALL DOWNLOADED ARTIFACTS ===="
          find artifacts -type f | sort
          echo "==== ARTIFACT DIRECTORIES ===="
          find artifacts -type d | sort
          echo "==== TOTAL FILE COUNT ===="
          find artifacts -type f | wc -l
          echo "==== TOTAL DIRECTORY COUNT ===="
          find artifacts -type d | wc -l

      - name: Get version info
        id: version
        uses: ./.github/actions/get-version-info

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ vars.AWS_REGION }}

      - name: Upload binaries to S3
        id: upload
        run: |
          # Define the S3 base prefix (typically "public")
          S3_BASE_PREFIX="${{ inputs.s3_base_prefix }}"
          
          # Path structure constants
          # 
          # We use different paths for S3 storage vs the manifest:
          # - S3 paths include the base prefix (typically "public") because that's how objects are stored in S3
          # - Manifest paths exclude the base prefix because CloudFront maps the base prefix as the root
          #   (e.g., get.bacalhau.org/ maps to s3://bucket/public/)
          
          # Define release type subdirectory based on target type
          case "${{ inputs.target_type }}" in
            edge)
              RELEASE_TYPE="edge"
              ;;
            nightly)
              RELEASE_TYPE="nightly"
              ;;
            release)
              if [[ "${{ steps.version.outputs.release_type }}" == "release" ]]; then
                RELEASE_TYPE="stable"
              else
                RELEASE_TYPE="pre"
              fi
              ;;
            *)
              echo "Unknown target type: ${{ inputs.target_type }}"
              exit 1
              ;;
          esac
          
          echo "Publishing to release type: $RELEASE_TYPE"
          echo "release_type=$RELEASE_TYPE" >> $GITHUB_OUTPUT
          
          # Derive the S3 path (with base prefix) and manifest path (without base prefix)
          S3_PATH="${S3_BASE_PREFIX}/releases/${RELEASE_TYPE}"
          MANIFEST_PATH="releases/${RELEASE_TYPE}"
          
          echo "S3 path: $S3_PATH"
          echo "Manifest path: $MANIFEST_PATH"
          echo "s3_path=$S3_PATH" >> $GITHUB_OUTPUT
          echo "manifest_path=$MANIFEST_PATH" >> $GITHUB_OUTPUT
          
          # Create a file to store the list of uploaded artifacts for the summary
          UPLOADS_LIST=""
          
          # Use the build date from the version action
          BUILD_DATE="${{ steps.version.outputs.build_date }}"
          GIT_VERSION="${{ steps.version.outputs.git_version }}"
          echo "Using build date from version info: $BUILD_DATE"
          echo "Using git version: $GIT_VERSION"
          
          # Process each artifact directory and upload to S3
          for dir in artifacts/bacalhau-*; do
            if [ -d "$dir" ]; then
              OS_ARCH=$(basename "$dir")
          
              # Extract OS and ARCH from directory name 
              if [[ "$OS_ARCH" =~ ^bacalhau-([^-]+)-([^-]+)$ ]]; then
                OS="${BASH_REMATCH[1]}"
                ARCH="${BASH_REMATCH[2]}"
              else
                echo "Skipping invalid directory name: $OS_ARCH"
                continue
              fi
          
              echo "Processing $OS/$ARCH"
          
              # Find artifacts (tarballs and signature files)
              ARTIFACTS=$(find "$dir" -name "*.tar.gz" -o -name "*.tar.gz.sig" -o -name "*.sig" -o -name "*.asc" -o -name "*.signature.sha256")
              if [ -z "$ARTIFACTS" ]; then
                echo "No artifacts found in $dir, skipping"
                continue
              fi
          
              # Process and upload each artifact found
              for ARTIFACT in $ARTIFACTS; do
                FILENAME=$(basename "$ARTIFACT")
          
                # Set metadata for S3 object
                METADATA="BuildDate=$BUILD_DATE,GOOS=$OS,GOARCH=$ARCH,GitCommit=${{ steps.version.outputs.git_commit }},GitVersion=$GIT_VERSION,Major=${{ steps.version.outputs.major }},Minor=${{ steps.version.outputs.minor }}"
          
                # Upload to target-specific path with original filename
                # Use the full S3 path (with base prefix)
                TARGET_S3_DEST="s3://${{ vars.S3_BUCKET }}/${S3_PATH}/${GIT_VERSION}/${FILENAME}"
                echo "Uploading to S3: $TARGET_S3_DEST"
                aws s3 cp "$ARTIFACT" "$TARGET_S3_DEST" --metadata "$METADATA"
          
                # For the upload list, we use the full S3 path for clarity
                UPLOADS_LIST="${UPLOADS_LIST}${S3_PATH}/${GIT_VERSION}/${FILENAME}|$OS/$ARCH|$BUILD_DATE\n"
              done
            fi
          done
          
          # Save uploads list for summary
          echo -e "$UPLOADS_LIST" > uploads_list.txt

      - name: Generate and upload release manifest
        id: manifest
        run: |
          RELEASE_TYPE="${{ steps.upload.outputs.release_type }}"
          # This is the path we'll use in the manifest (without the base prefix)
          MANIFEST_PATH="${{ steps.upload.outputs.manifest_path }}"
          GIT_VERSION="${{ steps.version.outputs.git_version }}"
          BUILD_DATE="${{ steps.version.outputs.build_date }}"
          
          echo "Creating manifest for $GIT_VERSION (Release type: $RELEASE_TYPE)"
          echo "Manifest path base: $MANIFEST_PATH"
          
          # Create JSON manifest using jq
          jq -n \
            --arg version "$GIT_VERSION" \
            --arg buildDate "$BUILD_DATE" \
            --arg gitCommit "${{ steps.version.outputs.git_commit }}" \
            --argjson major ${{ steps.version.outputs.major }} \
            --argjson minor ${{ steps.version.outputs.minor }} \
            '{
              "version": $version,
              "buildDate": $buildDate,
              "gitCommit": $gitCommit,
              "major": $major,
              "minor": $minor,
              "artifacts": {}
            }' > latest-manifest.json
          
          # Add artifact information for each OS/arch combination
          for dir in artifacts/bacalhau-*; do
            if [ -d "$dir" ]; then
              OS_ARCH=$(basename "$dir")
          
              if [[ "$OS_ARCH" =~ ^bacalhau-([^-]+)-([^-]+)$ ]]; then
                OS="${BASH_REMATCH[1]}"
                ARCH="${BASH_REMATCH[2]}"
          
                # Find the tarball for this OS/arch
                TARBALL=$(find "$dir" -name "*.tar.gz" | head -1)
                if [ -n "$TARBALL" ]; then
                  FILENAME=$(basename "$TARBALL")
          
                  # Create the path for the manifest (without the base prefix)
                  # This is the path as it will be accessed via CloudFront
                  TARGET_PATH="${MANIFEST_PATH}/${GIT_VERSION}/${FILENAME}"
          
                  # Check for signatures
                  SIGNATURES=()
                  SIG_FILES=$(find "$dir" -name "*.tar.gz.sig" -o -name "*.sig" -o -name "*.asc" -o -name "*.signature.sha256")
                  for SIG_FILE in $SIG_FILES; do
                    SIG_FILENAME=$(basename "$SIG_FILE")
          
                    # Path for signatures in the manifest (without the base prefix)
                    SIG_PATH="${MANIFEST_PATH}/${GIT_VERSION}/${SIG_FILENAME}"
                    SIGNATURES+=("\"$SIG_PATH\"")
                  done
          
                  # Join signature array into a comma-separated string
                  if [ ${#SIGNATURES[@]} -gt 0 ]; then
                    SIGNATURE_JSON="[$(echo "${SIGNATURES[@]}" | tr ' ' ',')]"
                  else
                    SIGNATURE_JSON="[]"
                  fi
          
                  # Add to the JSON using jq
                  jq --arg key "${OS}-${ARCH}" \
                     --arg filename "$FILENAME" \
                     --arg path "$TARGET_PATH" \
                     --arg os "$OS" \
                     --arg arch "$ARCH" \
                     --argjson signatures "$SIGNATURE_JSON" \
                     '.artifacts[$key] = {
                       "filename": $filename,
                       "path": $path,
                       "os": $os,
                       "arch": $arch,
                       "signatures": $signatures
                     }' latest-manifest.json > temp.json && mv temp.json latest-manifest.json
                fi
              fi
            fi
          done
          
          # Show the generated manifest for debugging
          echo "Generated manifest:"
          cat latest-manifest.json
          
          # Upload manifest to the manifests directory
          # The manifests are still stored in the public/ prefix for S3
          S3_BASE_PREFIX="${{ inputs.s3_base_prefix }}"
          aws s3 cp latest-manifest.json "s3://${{ vars.S3_BUCKET }}/${S3_BASE_PREFIX}/manifests/${RELEASE_TYPE}.json" \
            --metadata "LatestVersion=$GIT_VERSION,BuildDate=$BUILD_DATE" \
            --content-type "application/json"
          echo "Created manifest at s3://${{ vars.S3_BUCKET }}/${S3_BASE_PREFIX}/manifests/${RELEASE_TYPE}.json"

          # For stable releases, also publish a version-specific manifest (e.g., v1.7.x.json)
          if [[ "${{ inputs.target_type }}" == "release" && "${{ steps.version.outputs.release_type }}" == "release" ]]; then
            MAJOR="${{ steps.version.outputs.major }}"
            MINOR="${{ steps.version.outputs.minor }}"
            VERSION_SPECIFIC_MANIFEST="v${MAJOR}.${MINOR}.x.json"
            
            aws s3 cp latest-manifest.json "s3://${{ vars.S3_BUCKET }}/${S3_BASE_PREFIX}/manifests/${VERSION_SPECIFIC_MANIFEST}" \
              --metadata "LatestVersion=$GIT_VERSION,BuildDate=$BUILD_DATE" \
              --content-type "application/json"
            echo "Created version-specific manifest at s3://${{ vars.S3_BUCKET }}/${S3_BASE_PREFIX}/manifests/${VERSION_SPECIFIC_MANIFEST}"
          fi

      - name: Generate upload summary
        if: success()
        run: |
          echo "## S3 Upload Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "✅ Successfully uploaded binaries to S3" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Format metadata as a table for better readability
          echo "| Attribute | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|-----------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| **Target** | ${{ inputs.target_type }} |" >> $GITHUB_STEP_SUMMARY
          echo "| **Release Type** | ${{ steps.version.outputs.release_type }} |" >> $GITHUB_STEP_SUMMARY
          echo "| **S3 Bucket** | ${{ vars.S3_BUCKET }} |" >> $GITHUB_STEP_SUMMARY
          echo "| **S3 Region** | ${{ vars.AWS_REGION }} |" >> $GITHUB_STEP_SUMMARY
          echo "| **S3 Base Prefix** | ${{ inputs.s3_base_prefix }} |" >> $GITHUB_STEP_SUMMARY
          echo "| **Git Version** | ${{ steps.version.outputs.git_version }} |" >> $GITHUB_STEP_SUMMARY
          echo "| **Git Commit** | ${{ steps.version.outputs.git_commit }} |" >> $GITHUB_STEP_SUMMARY
          echo "| **Build Date** | ${{ steps.version.outputs.build_date }} |" >> $GITHUB_STEP_SUMMARY
          
          # Add manifest paths section if applicable
          RELEASE_TYPE="${{ steps.upload.outputs.release_type }}"
          S3_BASE_PREFIX="${{ inputs.s3_base_prefix }}"
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Release Manifests" >> $GITHUB_STEP_SUMMARY
          echo "| Type | S3 Path | CloudFront URL |" >> $GITHUB_STEP_SUMMARY
          echo "|------|---------|---------------|" >> $GITHUB_STEP_SUMMARY
          echo "| $RELEASE_TYPE | \`s3://${{ vars.S3_BUCKET }}/${S3_BASE_PREFIX}/manifests/${RELEASE_TYPE}.json\` | \`https://get.bacalhau.org/manifests/${RELEASE_TYPE}.json\` |" >> $GITHUB_STEP_SUMMARY

          # Add version-specific manifest if this is a stable release
          if [[ "${{ inputs.target_type }}" == "release" && "${{ steps.version.outputs.release_type }}" == "release" ]]; then
            MAJOR="${{ steps.version.outputs.major }}"
            MINOR="${{ steps.version.outputs.minor }}"
            VERSION_SPECIFIC_MANIFEST="v${MAJOR}.${MINOR}.x.json"
            echo "| v${MAJOR}.${MINOR}.x | \`s3://${{ vars.S3_BUCKET }}/${S3_BASE_PREFIX}/manifests/${VERSION_SPECIFIC_MANIFEST}\` | \`https://get.bacalhau.org/manifests/${VERSION_SPECIFIC_MANIFEST}\` |" >> $GITHUB_STEP_SUMMARY
          fi

          # Add uploaded files section
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Uploaded Files" >> $GITHUB_STEP_SUMMARY
          
          # Check if there are any files uploaded
          if [ -s uploads_list.txt ]; then
            # Count how many unique OS/ARCH combinations were uploaded
            PLATFORMS=$(cat uploads_list.txt | cut -d'|' -f2 | sort -u | wc -l)
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "Artifacts published for **$PLATFORMS** platforms:" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          
            # Create a markdown table with Platform, S3 Path, and CloudFront URL
            echo "| Platform | S3 Path | CloudFront URL |" >> $GITHUB_STEP_SUMMARY
            echo "|----------|---------|---------------|" >> $GITHUB_STEP_SUMMARY
          
            # Sort by platform for better readability
            sort -t'|' -k2 uploads_list.txt | while IFS='|' read -r S3_PATH PLATFORM BUILD_DATE; do
              # Skip any empty lines that might cause formatting issues
              if [[ -z "$PLATFORM" || -z "$S3_PATH" ]]; then
                continue
              fi
          
              # Convert S3 path to CloudFront URL by removing the base prefix
              # This assumes the base prefix is at the start of the path
              S3_BASE_PREFIX="${{ inputs.s3_base_prefix }}"
              CLOUDFRONT_PATH="${S3_PATH#$S3_BASE_PREFIX/}"
          
              # Add table row with platform, S3 path, and CloudFront URL
              echo "| $PLATFORM | \`s3://${{ vars.S3_BUCKET }}/$S3_PATH\` | \`https://get.bacalhau.org/$CLOUDFRONT_PATH\` |" >> $GITHUB_STEP_SUMMARY
            done
          else
            echo "No files were uploaded." >> $GITHUB_STEP_SUMMARY
          fi