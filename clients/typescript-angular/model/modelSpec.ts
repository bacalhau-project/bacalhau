/**
 * Bacalhau API
 * This page is the reference of the Bacalhau REST API. Project docs are available at https://docs.bacalhau.org/. Find more information about Bacalhau at https://github.com/filecoin-project/bacalhau.
 *
 * OpenAPI spec version: 1.0.0
 * Contact: team@bacalhau.org
 *
 * NOTE: This class is auto generated by the swagger code generator program.
 * https://github.com/swagger-api/swagger-codegen.git
 * Do not edit the class manually.
 */
import { ModelJobShardingConfig } from './modelJobShardingConfig';
import { ModelJobSpecDocker } from './modelJobSpecDocker';
import { ModelJobSpecLanguage } from './modelJobSpecLanguage';
import { ModelJobSpecWasm } from './modelJobSpecWasm';
import { ModelResourceUsageConfig } from './modelResourceUsageConfig';
import { ModelStorageSpec } from './modelStorageSpec';

export interface ModelSpec { 
    /**
     * Annotations on the job - could be user or machine assigned
     */
    annotations?: Array<string>;
    /**
     * Input volumes that will not be sharded for example to upload code into a base image every shard will get the full range of context volumes
     */
    contexts?: Array<ModelStorageSpec>;
    /**
     * Do not track specified by the client
     */
    doNotTrack?: boolean;
    docker?: ModelJobSpecDocker;
    /**
     * e.g. docker or language
     */
    engine?: number;
    language?: ModelJobSpecLanguage;
    /**
     * there can be multiple publishers for the job
     */
    publisher?: number;
    resources?: ModelResourceUsageConfig;
    sharding?: ModelJobShardingConfig;
    /**
     * How long a job can run in seconds before it is killed. This includes the time required to run, verify and publish results
     */
    timeout?: number;
    verifier?: number;
    wasm?: ModelJobSpecWasm;
    /**
     * the data volumes we will read in the job for example \"read this ipfs cid\" TODO: #667 Replace with \"Inputs\", \"Outputs\" (note the caps) for yaml/json when we update the n.js file
     */
    inputs?: Array<ModelStorageSpec>;
    /**
     * the data volumes we will write in the job for example \"write the results to ipfs\"
     */
    outputs?: Array<ModelStorageSpec>;
}